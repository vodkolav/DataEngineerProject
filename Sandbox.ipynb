{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sandbox  frim twitter producer\n",
    "below are cells that I played with to test portions of code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "int.encode(3423)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dir(str.encode('434234'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wat = str.encode('434g34')\n",
    "wat.isalnum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 99991231235\n",
    "#i=1\n",
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encode = lambda x : x.to_bytes(5, byteorder='big')\n",
    "decode = lambda x : int.from_bytes(x, byteorder='big')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ii = encode(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decode(encode(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decode(encode(i)) == i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int.from_bytes(hm, byteorder='big')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hm.isalnum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int(hm, base =2, byteorder='big')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traceback.extract_tb(oops.__traceback__ )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datefmt = \"%a %b %d %H:%M:%S %z %Y\"\n",
    "\n",
    "date = \"Sun Jan 13 23:03:23 +0000 2019\"\n",
    "\n",
    "def date_fmt_convert(date, fmt = \"%Y%m%d%H%M\"):        \n",
    "    # Convert twitter datetime format such as \n",
    "    # \"Sat Jan 4 11:39:13 +0500 2019\"\n",
    "    # to partitioning-compatible format and shift it to utc, so: \n",
    "    # int: 201901040639, int: \n",
    "    date_time_obj = datetime.strptime(date, datefmt)\n",
    "    date_time_obj.astimezone(tz=timezone.utc)\n",
    "    return int(date_time_obj.strftime(fmt)), int(date_time_obj.timestamp())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_fmt_convert(date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = stream.tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawdata = stream.rawdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wat = tweets\n",
    "print(len(wat))\n",
    "wat4 = wat[1]\n",
    "wat4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wat4[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wat4 = wat4.replace('1210547837035073536', '12105478370350735364305983475023948606723056927602')\n",
    "wat4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "watj = json.loads(wat4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "watj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id = wat4[1]['user']['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wat4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(json.loads(wat[i])['extended_tweet']['full_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(json.dumps(json.loads(wat[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    date_time_obj = datetime.strptime(date, self.datefmt)\n",
    "        date_time_obj = date_time_obj.astimezone(tz=timezone.utc)\n",
    "        return date_time_obj.strftime(\"%Y-%m-%d_%H-%M\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = wat4['tweet']['created_at']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " date_time_obj = datetime.strptime(date, \"%Y-%m-%d_%H-%M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(date_time_obj.timestamp())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_event = json.loads(wat4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_event['retweeted']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str_event = json.dumps(api_event, ensure_ascii=False)\n",
    "str_event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./test.json','w') as f:\n",
    "    str_event = json.dump(api_event,f, ensure_ascii=False)\n",
    "str_event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bytes(str_event, 'utf-8' ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wat[4]['retweeted_status']#['extended_tweet']['full_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook for playing with code snippets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import tweepy\n",
    "from datetime import datetime, timezone\n",
    "from kafka import KafkaProducer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_serializer=lambda v: json.dumps(v).encode()\n",
    "value_serializer(json.dumps('afgsfgsdfg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = \"Sat Jan 4 11:39:13 +0500 2019\"\n",
    "fmt = \"%a %b %d %H:%M:%S %z %Y\"\n",
    "date_time_obj = datetime.strptime(dat, fmt)\n",
    "(date_time_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_time_obj = date_time_obj.astimezone(tz=timezone.utc)\n",
    "date_time_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_time_obj.strftime(\"%Y-%m-%d_%H-%M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ified fields.\n",
    "Type:      builtin_function_or_method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Jun 28 2018 at 7:40AM\" -> \"%b %d %Y at %I:%M%p\"\n",
    "\"September 18, 2017, 22:19:55\" -> \"%B %d, %Y, %H:%M:%S\"\n",
    "\"Sun,05/12/99,12:30PM\" -> \"%a,%d/%m/%y,%I:%M%p\"\n",
    "\"Mon, 21 March, 2015\" -> \"%a, %d %B, %Y\"\n",
    "\"2018-03-12T10:12:45Z\" -> \"%Y-%m-%dT%H:%M:%SZ\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(api)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time, sleep\n",
    "print('sdfsd')\n",
    "for i in range(10):\n",
    "    sleep(.2)\n",
    "    print('\\r'+str(i),end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "id_of_tweet = \"1207211310456463360\"\n",
    "\n",
    "tweet = api.get_status(id_of_tweet, tweet_mode='extended')._json['full_text']\n",
    "print(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet._json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet2 = json.loads(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "            # Merge dictionaries\n",
    "#             user_events.update(twitter_events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsn = \"{\\\"user\\\": {\\\"id\\\": 1026860244, \\\"name\\\": \\\"Spaceman Spiff\\\", \\\"screen_name\\\": \\\"rajreddynyc\\\", \\\"location\\\": \\\"Queens, NY\\\", \\\"url\\\": null, \\\"protected\\\": false, \\\"verified\\\": false, \\\"followers_count\\\": 242, \\\"friends_count\\\": 54, \\\"listed_count\\\": 62, \\\"favourites_count\\\": 3108, \\\"statuses_count\\\": 193145, \\\"created_at\\\": \\\"Fri Dec 21 18:05:02 +0000 2012\\\"}, \\\"tweet\\\": {\\\"created_at\\\": \\\"Sat Dec 21 19:42:56 +0000 2019\\\", \\\"id\\\": 1208472941035438080, \\\"text\\\": \\\"@shambhav15 @Sanjay_Dixit the poem was like distributing nazi pamphlets in Israel.\\\", \\\"geo\\\": null, \\\"coordinates\\\": null, \\\"place\\\": null, \\\"quote_count\\\": 0, \\\"reply_count\\\": 0, \\\"retweet_count\\\": 0, \\\"favorite_count\\\": 0}}\"\n",
    "jsn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "json.loads(jsn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import sys\n",
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import explode\n",
    "from pyspark.sql.functions import split, from_json\n",
    "from time import time, sleep\n",
    "\n",
    "from pyspark.sql.types import StructType, StringType, MapType, StructField\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_keys = ['created_at', 'id', 'text', 'geo', 'coordinates', 'place',\n",
    "                          \"quote_count\", \"reply_count\", \"retweet_count\", \"favorite_count\" ]\n",
    "\n",
    "user_keys = ['id', 'name', 'screen_name','created_at', 'location', 'url',\n",
    "             'protected', 'verified', 'followers_count', 'friends_count',\n",
    "             'listed_count', 'favourites_count', 'statuses_count', 'withheld_in_countries']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType([\n",
    "    StructField(\"created_at\", StringType(), True),\n",
    "    StructField(\"id\", StringType(), True),\n",
    "    StructField(\"text\", StringType(), True),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get week number (week of the year)\n",
    "date_time_obj = datetime.strptime(\"2017-12-02 03:04:00\", \"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "date_time_obj.strftime(\"%V\")\n",
    "\n",
    "#datetime.today().strftime(\"%V\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow as pa\n",
    "fs = pa.hdfs.connect(\n",
    "    host='localhost', \n",
    "    port=8020, \n",
    "    user='hdfs', \n",
    "    kerb_ticket=None, \n",
    "    driver='libhdfs', \n",
    "    extra_conf=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usrs = \"/user/hive/warehouse/twitter.db/users_staging\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs.ls(usrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = fs.ls(usrs)[4]\n",
    "print(d)\n",
    "fs.mv(d, d.lower())\n",
    "\n",
    "fs.rename()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I had folders names like '/user/hive/warehouse/twitter.db/users_staging/created_Ym=200703'\n",
    "# but hive creates columns names in lower case, so it couldn't find  created_ym=200703\n",
    "# had to rename them in bulk\n",
    "\n",
    "for d in fs.ls(usrs):\n",
    "    print(d)\n",
    "    try:\n",
    "        fs.mv(d, d.lower())\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analytics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyhive import hive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdfs_host = 'localhost'\n",
    "hdfs_port = 9870\n",
    "hive_port = 10000\n",
    "hive_username = 'hdfs'\n",
    "hive_password = 'naya'\n",
    "hive_database = 'twitter'\n",
    "hive_mode = 'CUSTOM'\n",
    "\n",
    "hive_cnx = hive.Connection(\n",
    "  host = hdfs_host, \n",
    "  port = hive_port, \n",
    "  username = hive_username,\n",
    "  password = hive_password,\n",
    "  auth = hive_mode,\n",
    "  database = hive_database )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = f\"select user_id from tweets \"\n",
    "res = ''\n",
    "with hive_cnx.cursor() as cursor:\n",
    "    cursor.execute(q)\n",
    "    res = cursor.fetchall()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = [r[0] for r in res]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "plt.plot(A, '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "A1 = np.array(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = A1[A1<6e16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(B, '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(A1,bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(B,bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A1.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wat = int(4523454056235238756239857623587263450238672309276028762034123125345245234562346363452345234523452345.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#how to print with colored text\n",
    "\n",
    "class bcolors:\n",
    "    HEADER = '\\033[95m'\n",
    "    OKBLUE = '\\033[94m'\n",
    "    OKGREEN = '\\033[92m'\n",
    "    WARNING = '\\033[93m'\n",
    "    FAIL = '\\033[91m'\n",
    "    ENDC = '\\033[0m'\n",
    "    BOLD = '\\033[1m'\n",
    "    UNDERLINE = '\\033[4m'\n",
    "    \n",
    "print(bcolors.OKGREEN + \"Warning: No active frommets remain. Continue?\" + bcolors.ENDC + \"kapisch?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analytics on Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyhive import hive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdfs_host = 'localhost'\n",
    "hdfs_port = 9870\n",
    "hive_port = 10000\n",
    "hive_username = 'hdfs'\n",
    "hive_password = 'naya'\n",
    "hive_database = 'twitter'\n",
    "hive_mode = 'CUSTOM'\n",
    "\n",
    "hive_cnx = hive.Connection(\n",
    "  host = hdfs_host, \n",
    "  port = hive_port, \n",
    "  username = hive_username,\n",
    "  password = hive_password,\n",
    "  auth = hive_mode,\n",
    "  database = hive_database )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = f\"select id, created_at from users \"\n",
    "res = ''\n",
    "with hive_cnx.cursor() as cursor:\n",
    "    cursor.execute(q)\n",
    "    res = cursor.fetchall()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "len(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = [r[0] for r in res]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "A = pd.DataFrame(res, columns=('id','ts'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timezone\n",
    "def timeStamp_fmt_convert(date):        \n",
    "    # Convert twitter datetime format such as \n",
    "    # \"Sat Jan 4 11:39:13 +0500 2019\"\n",
    "    # to partitioning-compatible format and shift it to utc, so: \n",
    "    # \"2017-12-02 03:04:00\"\n",
    "    date_time_obj = datetime.strptime(date, \"%a %b %d %H:%M:%S %z %Y\")\n",
    "    date_time_obj.astimezone(tz=timezone.utc)\n",
    "    return date_time_obj.timestamp()#.strftime(\"%Y-%m-%d %H:%M:%S\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = [timeStamp_fmt_convert(a) for a in A['ts']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wat = ts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(wat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A['ts'] = ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "\n",
    "x = A['ts']\n",
    "y = A['id']\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%m/%d/%Y'))\n",
    "plt.gca().xaxis.set_major_locator(mdates.DayLocator())\n",
    "plt.plot(x,y)\n",
    "plt.gcf().autofmt_xdate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(A['ts'],A['id'], '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = A[A['id']>2e17]\n",
    "\n",
    "len(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(B['ts'],B['id'], '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(A['ts'],bins = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyhive import hive\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "%matplotlib notebook\n",
    "\n",
    "from itertools import count\n",
    "import numpy as np\n",
    "\n",
    "n = 1000\n",
    "\n",
    "tweets1 = list(range(n))\n",
    "tweets2 = np.random.randn(n)\n",
    "tweets3 = np.random.randn(n)\n",
    "\n",
    "t = pd.DataFrame(list(zip(tweets1, tweets2, tweets3)),  columns = [\"a\",\"b\",\"c\"] )\n",
    "\n",
    "\n",
    "\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "x = []\n",
    "y1 = []\n",
    "y2 = []\n",
    "\n",
    "index = count()\n",
    "\n",
    "plt.plot([], [], label='Channel 1')\n",
    "plt.plot([], [], label='Channel 2')\n",
    "\n",
    "\n",
    "def animate(i):\n",
    "    data = t[:i]\n",
    "    x = data['a']\n",
    "    y1 = data['b']\n",
    "    y2 = data['c']\n",
    "\n",
    "    plt.cla()\n",
    "\n",
    "    plt.scatter(y1,x, label='Channel 1')\n",
    "    plt.scatter(y2,x, label='Channel 2')\n",
    "\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.tight_layout()\n",
    "    plt.xlim = [-5,5]\n",
    "    plt.ylim = [0,i+1]\n",
    "\n",
    "ani = FuncAnimation(plt.gcf(), animate, frames=range(1,n), interval=100)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_temp():\n",
    "    return np.random.rand(1)[0]\n",
    "read_temp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import tmp102\n",
    "\n",
    "# Parameters\n",
    "x_len = 200         # Number of points to display\n",
    "y_range = [-5,5]  # Range of possible Y values to display\n",
    "\n",
    "# Create figure for plotting\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "xs = list(range(0, 200))\n",
    "ys = [0] * x_len\n",
    "ax.set_ylim(y_range)\n",
    "\n",
    "\n",
    "# Initialize communication with TMP102\n",
    "#tmp102.init()\n",
    "\n",
    "# Create a blank line. We will update the line in animate\n",
    "line, = ax.plot(xs, ys)\n",
    "\n",
    "# Add labels\n",
    "plt.title('TMP102 Temperature over Time')\n",
    "plt.xlabel('Samples')\n",
    "plt.ylabel('Temperature (deg C)')\n",
    "\n",
    "# This function is called periodically from FuncAnimation\n",
    "def animate(i, ys):\n",
    "\n",
    "    # Read temperature (Celsius) from TMP102\n",
    "    temp_c = round(read_temp(), 2)\n",
    "\n",
    "    # Add y to list\n",
    "    ys.append(temp_c)\n",
    "\n",
    "    # Limit y list to set number of items\n",
    "    ys = ys[-x_len:]\n",
    "\n",
    "    # Update line with new Y values\n",
    "    line.set_ydata(ys)\n",
    "\n",
    "    return line,\n",
    "\n",
    "# Set up plot to call animate() function periodically\n",
    "ani = animation.FuncAnimation(fig,\n",
    "    animate,\n",
    "    fargs=(ys,),\n",
    "    interval=50,\n",
    "    blit=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt \n",
    "from matplotlib import dates as mdates\n",
    "from datetime import datetime\n",
    "Data=['16:24:00',\n",
    "     '17:48:00',\n",
    "     '16:10:00',\n",
    "     '16:46:00',\n",
    "     '17:13:00',\n",
    "     '15:31:00',\n",
    "     '16:23:00',\n",
    "     '16:53:00',\n",
    "     '16:28:00',\n",
    "     '16:33:00',\n",
    "     '17:38:00',\n",
    "     '17:08:00',\n",
    "     '16:29:00',\n",
    "     '16:25:00',\n",
    "     '16:17:00',\n",
    "     '17:38:00',\n",
    "     '16:29:00']\n",
    "#convert strings into datetime objects\n",
    "conv_time = [datetime.strptime(i, \"%H:%M:%S\") for i in Data]\n",
    "#define bin number\n",
    "bin_nr = 7\n",
    "fig, ax = plt.subplots(1,1)\n",
    "#create histogram, get bin position for label\n",
    "_counts, bins, _patches = ax.hist(conv_time, bins = bin_nr)\n",
    "#set xticks at bin edges\n",
    "plt.xticks(bins)\n",
    "#reformat bin label into format hour:minute\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter(\"%H:%M\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time\n",
    "import threading, queue\n",
    "\n",
    "class WorkerThread(threading.Thread):\n",
    "    \"\"\" A worker thread that takes directory names from a queue, finds all\n",
    "        files in them recursively and reports the result.\n",
    "\n",
    "        Input is done by placing directory names (as strings) into the\n",
    "        Queue passed in dir_q.\n",
    "\n",
    "        Output is done by placing tuples into the Queue passed in result_q.\n",
    "        Each tuple is (thread name, dirname, [list of files]).\n",
    "\n",
    "        Ask the thread to stop by calling its join() method.\n",
    "    \"\"\"\n",
    "    def __init__(self, dir_q, result_q):\n",
    "        super(WorkerThread, self).__init__()\n",
    "        self.dir_q = dir_q\n",
    "        self.result_q = result_q\n",
    "        self.stoprequest = threading.Event()\n",
    "        self.data =0\n",
    "        print(self.name + \" initialized\")\n",
    "    def run(self):\n",
    "        # As long as we weren't asked to stop, try to take new tasks from the\n",
    "        # queue. The tasks are taken with a blocking 'get', so no CPU\n",
    "        # cycles are wasted while waiting.\n",
    "        # Also, 'get' is given a timeout, so stoprequest is always checked,\n",
    "        # even if there's nothing in the queue.\n",
    "        while not self.stoprequest.isSet():\n",
    "            try:\n",
    "                num = self.dir_q.get(True, 0.05)\n",
    "                print(self.name + \" counts to \" + str(num))\n",
    "                numlist = list(self._count(num))\n",
    "                self.result_q.put((self.name, num, numlist))\n",
    "            except queue.Empty:\n",
    "                continue\n",
    "    def start(self):\n",
    "        print(self.name + \" started\")\n",
    "        super(WorkerThread, self).start()\n",
    "                \n",
    "    def join(self, timeout=None):\n",
    "        self.stoprequest.set()\n",
    "        print(self.name + \" X_X\")\n",
    "        super(WorkerThread, self).join(timeout)\n",
    "\n",
    "    def _count(self, to):\n",
    "        for i in range(to):\n",
    "            time.sleep(1)\n",
    "            #print(\"\\r\" + str(i), end = '')\n",
    "            self.data = i\n",
    "            yield i\n",
    "    def ask(self):\n",
    "        return self.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thread-6 initialized\n"
     ]
    }
   ],
   "source": [
    "# def main(args):\n",
    "# Create a single input and a single output queue for all threads.\n",
    "dir_q = queue.Queue()\n",
    "result_q = queue.Queue()\n",
    "\n",
    "# Create the \"thread pool\"\n",
    "pool = [WorkerThread(dir_q=dir_q, result_q=result_q) for i in range(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thread-6 started\n"
     ]
    }
   ],
   "source": [
    "# Start all threads\n",
    "for thread in pool:\n",
    "    thread.start()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool[0].run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thread-6 counts to 5\n",
      "Thread-6 counts to 6\n",
      "Thread-6 counts to 7\n",
      "Thread-6 counts to 8\n",
      "Thread-6 counts to 9\n"
     ]
    }
   ],
   "source": [
    "pool[0].ask()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-df5ffcdda271>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mthread\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mthread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\r\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/ipykernel/iostream.py\u001b[0m in \u001b[0;36mwrite\u001b[0;34m(self, string)\u001b[0m\n\u001b[1;32m    398\u001b[0m             \u001b[0mis_child\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_master_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m             \u001b[0;31m# only touch the buffer in the IO thread to avoid races\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 400\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpub_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    401\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_child\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m                 \u001b[0;31m# newlines imply flush in subprocesses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/ipykernel/iostream.py\u001b[0m in \u001b[0;36mschedule\u001b[0;34m(self, f)\u001b[0m\n\u001b[1;32m    201\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_events\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0;31m# wake event thread (message content is ignored)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event_pipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, data, flags, copy, track, routing_id, group)\u001b[0m\n\u001b[1;32m    393\u001b[0m                                  copy_threshold=self.copy_threshold)\n\u001b[1;32m    394\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSocket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    396\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msend_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg_parts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._send_copy\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    for thread in pool:\n",
    "        a= thread.ask()\n",
    "        print(\"\\r\" + str(a), end = '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assigned 6 nums to workers\n",
      "Thread-6 counts to 60\n"
     ]
    }
   ],
   "source": [
    "nums = [60, 5, 6, 7, 8, 9]\n",
    "# Give the workers some work to do\n",
    "work_count = 0\n",
    "for n in nums:\n",
    "    work_count += 1\n",
    "    dir_q.put(n)\n",
    "\n",
    "print(f'Assigned {work_count} nums to workers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From thread Thread-6: 4 files found in dir 4\n",
      "From thread Thread-8: 5 files found in dir 5\n",
      "From thread Thread-7: 6 files found in dir 6\n",
      "From thread Thread-9: 7 files found in dir 7\n",
      "From thread Thread-5: 8 files found in dir 8\n",
      "From thread Thread-4: 9 files found in dir 9\n"
     ]
    }
   ],
   "source": [
    "# Now get all the results\n",
    "while work_count > 0:\n",
    "    # Blocking 'get' from a Queue.\n",
    "    result = result_q.get()\n",
    "    print('From thread %s: %s files found in dir %s' % (result[0], len(result[2]), result[1]))\n",
    "    work_count -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thread-4 X_X\n",
      "Thread-5 X_X\n",
      "Thread-6 X_X\n",
      "Thread-7 X_X\n",
      "Thread-8 X_X\n",
      "Thread-9 X_X\n"
     ]
    }
   ],
   "source": [
    "# Ask threads to die and wait for them to do it\n",
    "for thread in pool:\n",
    "    thread.join()\n",
    "\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     import sys\n",
    "#     main(sys.argv[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
